{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.5.1 (from gradio)\n",
      "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\azamora\\appdata\\local\\anaconda3\\envs\\py312\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.12-cp312-none-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\azamora\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\azamora\\appdata\\local\\anaconda3\\envs\\py312\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.8.2-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typing-extensions~=4.0 (from gradio)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.5.1->gradio)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.1->gradio)\n",
      "  Downloading websockets-14.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0,>=3.0->gradio)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting certifi (from httpx>=0.24.1->gradio)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.25.1->gradio)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests (from huggingface-hub>=0.25.1->gradio)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.25.1->gradio)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\azamora\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\azamora\\appdata\\local\\anaconda3\\envs\\py312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\azamora\\appdata\\local\\anaconda3\\envs\\py312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\azamora\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\azamora\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\azamora\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.25.1->gradio)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.25.1->gradio)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
      "   ---------------------------------------- 0.0/57.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 4.5/57.2 MB 29.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 12.8/57.2 MB 32.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 19.7/57.2 MB 31.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 25.7/57.2 MB 30.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 33.3/57.2 MB 31.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 40.1/57.2 MB 31.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 46.1/57.2 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 52.7/57.2 MB 31.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  57.1/57.2 MB 31.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 57.2/57.2 MB 29.4 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Downloading orjson-3.10.12-cp312-none-win_amd64.whl (135 kB)\n",
      "Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 29.6 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading ruff-0.8.2-py3-none-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 6.6/9.6 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 29.8 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading websockets-14.1-cp312-cp312-win_amd64.whl (163 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, urllib3, typing-extensions, tqdm, tomlkit, sniffio, shellingham, semantic-version, ruff, pyyaml, python-multipart, pillow, orjson, mdurl, markupsafe, idna, h11, fsspec, filelock, ffmpy, click, charset-normalizer, certifi, annotated-types, aiofiles, uvicorn, requests, pydantic-core, markdown-it-py, jinja2, httpcore, anyio, starlette, rich, pydantic, huggingface-hub, httpx, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.7.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 fastapi-0.115.6 ffmpy-0.4.0 filelock-3.16.1 fsspec-2024.10.0 gradio-5.8.0 gradio-client-1.5.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.0 huggingface-hub-0.26.3 idna-3.10 jinja2-3.1.4 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 orjson-3.10.12 pillow-11.0.0 pydantic-2.10.3 pydantic-core-2.27.1 pydub-0.25.1 python-multipart-0.0.19 pyyaml-6.0.2 requests-2.32.3 rich-13.9.4 ruff-0.8.2 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.41.3 tomlkit-0.13.2 tqdm-4.67.1 typer-0.15.1 typing-extensions-4.12.2 urllib3-2.2.3 uvicorn-0.32.1 websockets-14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azamora\\AppData\\Local\\anaconda3\\envs\\py312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Import the required dependencies from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Set the column width to view the text message data.\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "# Import Gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sms_classification(sms_text_df):\n",
    "    \"\"\"\n",
    "    Perform SMS classification using a pipeline with TF-IDF vectorization and Linear Support Vector Classification.\n",
    "\n",
    "    Parameters:\n",
    "    - sms_text_df (pd.DataFrame): DataFrame containing 'text_message' and 'label' columns for SMS classification.\n",
    "\n",
    "    Returns:\n",
    "    - text_clf (Pipeline): Fitted pipeline model for SMS classification.\n",
    "\n",
    "    This function takes a DataFrame with 'text_message' and 'label' columns, splits the data into\n",
    "    training and testing sets, builds a pipeline with TF-IDF vectorization and Linear Support Vector\n",
    "    Classification, and fits the model to the training data. \n",
    "    The fitted pipeline is returned to make future predictions.\n",
    "    \"\"\"\n",
    "    # Set the features variable to the text message column.\n",
    "    features = sms_text_df['text_message']\n",
    "    \n",
    "    # Set the target variable to the \"label\" column.\n",
    "    target = sms_text_df['label']\n",
    "   \n",
    "\n",
    "    # Split data into training and testing and set the test_size = 33%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=42)\n",
    "    \n",
    "\n",
    "    # Build a pipeline to transform the test set to compare to the training set.\n",
    "    text_clf = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', LinearSVC())\n",
    "    ])\n",
    "    \n",
    "\n",
    "    # Fit the model to the transformed training data and return model.\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                  text_message  \n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3                                                                                                            U dun say so early hor... U c already then say...  \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "sms_text_df = pd.read_csv('Resources/SMSSpamCollection.csf')\n",
    "sms_text_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sms_text_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Call the sms_classification function with the DataFrame and set the result to the \"text_clf\" variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m text_clf \u001b[38;5;241m=\u001b[39m sms_classification(\u001b[43msms_text_df\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sms_text_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Call the sms_classification function with the DataFrame and set the result to the \"text_clf\" variable\n",
    "text_clf = sms_classification(sms_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called `sms_prediction` that takes in the SMS text and predicts the whether the text is \"not spam\" or \"spam\". \n",
    "# The function should return the SMS message, and say whether the text is \"not spam\" or \"spam\".\n",
    "def sms_prediction(text):\n",
    "    \"\"\"\n",
    "    Predict the spam/ham classification of a given text message using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text message to be classified.\n",
    "\n",
    "    Returns:\n",
    "    - str: A message indicating whether the text message is classified as spam or not.\n",
    "\n",
    "    This function takes a text message and a pre-trained pipeline model, then predicts the\n",
    "    spam/ham classification of the text. The result is a message stating whether the text is\n",
    "    classified as spam or not.\n",
    "    \"\"\"\n",
    "    # Create a variable that will hold the prediction of a new text.\n",
    "    \n",
    "    # Using a conditional if the prediction is \"ham\" return the message:\n",
    "    # f'The text message: \"{text}\", is not spam.' Else, return f'The text message: \"{text}\", is spam.'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sms_app that takes a textbox for the inputs and has a textbox for the output.  \n",
    "# Povide labels for each textbox. \n",
    "\n",
    "    \n",
    "# Launch the app.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the following text messages. \n",
    "\n",
    "---\n",
    "\n",
    "1. You are a lucky winner of $5000!\n",
    "2. You won 2 free tickets to the Super Bowl.\n",
    "3. You won 2 free tickets to the Super Bowl text us to claim your prize.\n",
    "4. Thanks for registering. Text 4343 to receive free updates on medicare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
